{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Affect Reconition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import opencv_jupyter_ui as jcv2\n",
    "from feat import Detector\n",
    "from IPython.display import Image\n",
    "\n",
    "\n",
    "from feat.utils import FEAT_EMOTION_COLUMNS\n",
    "from feat.pretrained import AU_LANDMARK_MAP\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading Face model: retinaface\n",
      "g:\\My Drive\\Uppsala\\IIS\\venv\\Lib\\site-packages\\feat\\face_detectors\\Retinaface\\Retinaface_test.py:70: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pretrained_dict = torch.load(\n",
      "INFO:root:Loading Facial Landmark model: mobilefacenet\n",
      "g:\\My Drive\\Uppsala\\IIS\\venv\\Lib\\site-packages\\feat\\detector.py:224: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\n",
      "INFO:root:Loading facepose model: img2pose\n",
      "g:\\My Drive\\Uppsala\\IIS\\venv\\Lib\\site-packages\\feat\\facepose_detectors\\img2pose\\img2pose_test.py:105: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path, map_location=self.device)\n",
      "INFO:root:Loading AU model: xgb\n",
      "INFO:root:Loading emotion model: resmasknet\n",
      "g:\\My Drive\\Uppsala\\IIS\\venv\\Lib\\site-packages\\feat\\emo_detectors\\ResMaskNet\\resmasknet_test.py:718: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(\n"
     ]
    }
   ],
   "source": [
    "detector = Detector(device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "# emotion read as string\n",
    "df = pd.read_csv(\"dataset.csv\", dtype={\"emotion\": str})\n",
    "\n",
    "\n",
    "\n",
    "# get the list of emotions\n",
    "emotions = df['emotion'].unique()\n",
    "\n",
    "# encode the emotions as integers\n",
    "emotion_to_int = {emotion: i for i, emotion in enumerate(emotions)}\n",
    "\n",
    "# features: AU01,AU02,AU04,AU05,AU06,AU07,AU09,AU10,AU11,AU12,AU14,AU15,AU17,AU20,AU23,AU24,AU25,AU26,AU28,AU43\n",
    "# labels: emotion\n",
    "features = df[AU_LANDMARK_MAP[\"Feat\"]].values\n",
    "labels = df['emotion'].map(emotion_to_int).values\n",
    "\n",
    "# convert to numpy arrays\n",
    "features = np.array(features)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Train/val/test split percentage: 70/20/10\n",
    "train_size = int(0.7 * len(df))\n",
    "val_size = int(0.2 * len(df))\n",
    "test_size = len(df) - train_size - val_size\n",
    "\n",
    "# split the data\n",
    "train_features, val_features, test_features = features[:train_size], features[train_size:train_size+val_size], features[train_size+val_size:]\n",
    "train_labels, val_labels, test_labels = labels[:train_size], labels[train_size:train_size+val_size], labels[train_size+val_size:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features shape: (812, 20)\n",
      "Train labels shape: (812,)\n",
      "Val features shape: (232, 20)\n",
      "Val labels shape: (232,)\n",
      "Test features shape: (117, 20)\n",
      "Test labels shape: (117,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train features shape:\", train_features.shape)\n",
    "print(\"Train labels shape:\", train_labels.shape)\n",
    "print(\"Val features shape:\", val_features.shape)\n",
    "print(\"Val labels shape:\", val_labels.shape)\n",
    "print(\"Test features shape:\", test_features.shape)\n",
    "print(\"Test labels shape:\", test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn model: Support Vector Machines (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy for SVC (kernel='linear'): 0.5862068965517241\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# SVC with linear kernel\n",
    "# train the model\n",
    "model_SVC_linear = SVC(kernel='linear')\n",
    "model_SVC_linear.fit(train_features, train_labels)\n",
    "\n",
    "# predict the validation set\n",
    "val_predictions = model_SVC_linear.predict(val_features)\n",
    "\n",
    "# calculate the accuracy\n",
    "accuracy = accuracy_score(val_labels, val_predictions)\n",
    "print(f\"Validation Accuracy for SVC (kernel='linear'): {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy for SVC (kernel='rbf'): 0.5905172413793104\n"
     ]
    }
   ],
   "source": [
    "# SVC with RBF kernel\n",
    "# train the model\n",
    "model_SVC_rbf = SVC(kernel='rbf')\n",
    "model_SVC_rbf.fit(train_features, train_labels)\n",
    "\n",
    "# predict the validation set\n",
    "val_predictions = model_SVC_rbf.predict(val_features)\n",
    "\n",
    "# calculate the accuracy\n",
    "accuracy = accuracy_score(val_labels, val_predictions)\n",
    "print(f\"Validation Accuracy for SVC (kernel='rbf'): {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy for SVC (kernel='poly'): 0.5862068965517241\n"
     ]
    }
   ],
   "source": [
    "# SVC with poly kernel\n",
    "# train the model\n",
    "model_SVC_poly = SVC(kernel='poly')\n",
    "model_SVC_poly.fit(train_features, train_labels)\n",
    "\n",
    "# predict the validation set\n",
    "val_predictions = model_SVC_poly.predict(val_features)\n",
    "\n",
    "# calculate the accuracy\n",
    "accuracy = accuracy_score(val_labels, val_predictions)\n",
    "print(f\"Validation Accuracy for SVC (kernel='poly'): {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy for SVC (kernel='sigmoid'): 0.2025862068965517\n"
     ]
    }
   ],
   "source": [
    "# SVC with sigmoid kernel\n",
    "# train the model\n",
    "model_SVC_sigmoid = SVC(kernel='sigmoid')\n",
    "model_SVC_sigmoid.fit(train_features, train_labels)\n",
    "\n",
    "# predict the validation set\n",
    "val_predictions = model_SVC_sigmoid.predict(val_features)\n",
    "\n",
    "# calculate the accuracy\n",
    "accuracy = accuracy_score(val_labels, val_predictions)\n",
    "print(f\"Validation Accuracy for SVC (kernel='sigmoid'): {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy for SVC (kernel='precomputed'): 0.5862068965517241\n"
     ]
    }
   ],
   "source": [
    "# SVC with precomputed kernel\n",
    "# train the model\n",
    "model_SVC_precomputed = SVC(kernel='precomputed')\n",
    "model_SVC_precomputed.fit(train_features @ train_features.T, train_labels)\n",
    "\n",
    "# predict the validation set\n",
    "val_predictions = model_SVC_precomputed.predict(val_features @ train_features.T)\n",
    "\n",
    "# calculate the accuracy\n",
    "accuracy = accuracy_score(val_labels, val_predictions)\n",
    "print(f\"Validation Accuracy for SVC (kernel='precomputed'): {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy for SVC (kernel='rbf'): 0.5982905982905983\n"
     ]
    }
   ],
   "source": [
    "# SVC test accuracy with rbf kernel\n",
    "test_predictions = model_SVC_rbf.predict(test_features)\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "print(f\"Test Accuracy for SVC (kernel='rbf'): {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy for KNN (k=1): 0.5387931034482759\n",
      "Validation Accuracy for KNN (k=3): 0.5517241379310345\n",
      "Validation Accuracy for KNN (k=5): 0.5301724137931034\n",
      "Validation Accuracy for KNN (k=7): 0.5646551724137931\n",
      "Validation Accuracy for KNN (k=9): 0.5301724137931034\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# KNN with k=1\n",
    "# train the model\n",
    "\n",
    "model_KNN_1 = KNeighborsClassifier(n_neighbors=1)\n",
    "model_KNN_1.fit(train_features, train_labels)\n",
    "\n",
    "# predict the validation set\n",
    "val_predictions = model_KNN_1.predict(val_features)\n",
    "\n",
    "\n",
    "# calculate the accuracy\n",
    "accuracy = accuracy_score(val_labels, val_predictions)\n",
    "print(f\"Validation Accuracy for KNN (k=1): {accuracy}\")\n",
    "\n",
    "# KNN with k=3\n",
    "# train the model\n",
    "model_KNN_3 = KNeighborsClassifier(n_neighbors=3)\n",
    "model_KNN_3.fit(train_features, train_labels)\n",
    "\n",
    "# predict the validation set\n",
    "val_predictions = model_KNN_3.predict(val_features)\n",
    "\n",
    "\n",
    "# calculate the accuracy\n",
    "accuracy = accuracy_score(val_labels, val_predictions)\n",
    "print(f\"Validation Accuracy for KNN (k=3): {accuracy}\")\n",
    "\n",
    "\n",
    "# KNN with k=5\n",
    "# train the model\n",
    "model_KNN_5 = KNeighborsClassifier(n_neighbors=5)\n",
    "model_KNN_5.fit(train_features, train_labels)\n",
    "\n",
    "# predict the validation set\n",
    "val_predictions = model_KNN_5.predict(val_features)\n",
    "\n",
    "\n",
    "# calculate the accuracy\n",
    "accuracy = accuracy_score(val_labels, val_predictions)\n",
    "print(f\"Validation Accuracy for KNN (k=5): {accuracy}\")\n",
    "\n",
    "# KNN with k=7\n",
    "# train the model\n",
    "model_KNN_7 = KNeighborsClassifier(n_neighbors=7)\n",
    "model_KNN_7.fit(train_features, train_labels)\n",
    "\n",
    "# predict the validation set\n",
    "val_predictions = model_KNN_7.predict(val_features)\n",
    "\n",
    "\n",
    "\n",
    "# calculate the accuracy\n",
    "accuracy = accuracy_score(val_labels, val_predictions)\n",
    "print(f\"Validation Accuracy for KNN (k=7): {accuracy}\")\n",
    "# KNN with k=9\n",
    "# train the model\n",
    "model_KNN_9 = KNeighborsClassifier(n_neighbors=9)\n",
    "model_KNN_9.fit(train_features, train_labels)\n",
    "\n",
    "# predict the validation set\n",
    "val_predictions = model_KNN_9.predict(val_features)\n",
    "\n",
    "\n",
    "# calculate the accuracy\n",
    "accuracy = accuracy_score(val_labels, val_predictions)\n",
    "print(f\"Validation Accuracy for KNN (k=9): {accuracy}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy for KNN (k=7): 0.5897435897435898\n"
     ]
    }
   ],
   "source": [
    "#TEST\n",
    "# KNN test accuracy with k=7\n",
    "\n",
    "test_predictions = model_KNN_7.predict(test_features)\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "print(f\"Test Accuracy for KNN (k=7): {test_accuracy}\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
