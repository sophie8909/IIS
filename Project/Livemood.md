# Livemood

## Authors

Ting-Hsuan Lien, Tzu-Hsiang Kao, Cheng-Han Shen

## Date

November 17, 2024 

## Context

### Elevator Pitch

This project aims to develop a chatbot system capable of recognizing users emotional states in real time and delivering socially adaptive interactions

### Objectives

The primary goal of this project is to create a system that integrates real-time facial emotion detection with a conversational agent. By deep learning and natural language processing, we will ensure accurate emotion recognition and implement contextually appropriate responses through Furhat’s behavior module. 

### Deliverables

The completed project will deliver an integrated system that includes the emotion detection module with accompanying source code and documentation, the interaction behavior logic for Furhat, and a comprehensive demonstration video. 

### Success Metrics

The success of the project will be determined by achieving an 70% accuracy in emotion recognition using benchmark datasets and demonstrating a fully functional system that smoothly integrates all components.

### Potential Issues

The computational resources required for training models, potential environmental factors like lighting that could affect real-time recognition, and the iterative design process needed to create natural and adaptive responses for Furhat. 

## Specialisation

The project will specialize in accurately detecting user emotions and integrating a trained Large Language Model (LLM) to ensure Furhat provides precise and meaningful conversational responses, thereby enhancing the interaction subsystem. 

 Py-Feat detector 曾測臉部表情，結果跟人說得放到LLM  



LLM input: 臉部情緒偵測的文字結果，user input text

LLM structured output: gesture, output text for furhat json

LLM prompt: 3 different personity with full background story, information security prompt

model: Gemini 1.0 Pro, text natural language

model: Gemini 1.5 flash

- friendly 
- ESFJ
- ENTP
- Infp



## Project Breakdown

2024/11/27: Submit the proposal project specifications. 

2024/12/18: Complete the implementation of facial feature extraction and emotion recognition. 

2025/01/09: Finalize the integration of Furhat's adaptive behavior module and interaction design. 

2025/01/15: Submit the final report and deliver the system demonstration. 

